# word2vec 论文精读

Efficient Estimation of Word Representations in Vector Space - 向量空间中词表示的有效估计

本篇论文是 2013 年发表在 ICLR 上的论文。在NLP领域拥有里程碑式的意义，以至于后期的ELMo、Bert、GPT都是受词向量的影响而诞生的。同时本篇论文也是受到神经语言模型NNLM的启发。

- 出处：https://arxiv.org/abs/1301.3781

- 作者：Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean

- 单位：Google

- 发表年份：2013年

------

## 摘要

我们提出了两种创新的模型结构，用于生成来自庞大数据集的单词连续向量表示。这些表示的质量通过**单词相似性任务**进行评估，并与以往基于不同类型神经网络的最佳性能技术进行了比较。我们观察到，在计算成本显著降低的情况下，准确性显著提升，即便是从包含 16 亿个单词的数据集中学得高质量的单词向量也只需不到一天的时间。此外，我们证明这些向量在我们的测试集上展现出了领先水平，尤其在测量句法和语义单词相似性方面。



## 1 Introduction 

>介绍

当前许多 NLP 系统和技术将单词视为原子单元，即单词之间没有相似性的概念，因为它们在词汇表中表示为索引。这种方法有几个优点——简单性、鲁棒性 并且 观察到在大量数据上训练的简单模型优于在较少数据上训练的复杂系统。例如用于统计语言建模的流行 N-gram 模型 ，如今，可以在几乎所有可用数据（数万亿个单词）上训练 N-gram。



然而，这种简单的技术在许多任务中都存在局限性。例如，自动语音识别的相关域内数据量是有限的—性能通常由高质量转录语音数据的大小（通常只有数百万个单词）决定。在机器翻译中，许多语言的现有语料库仅包含数十亿个单词或更少。因此，在某些情况下，简单地扩展基本技术不会带来任何重大进展，我们必须关注更先进的技术。



近年来，随着机器学习技术的进步，在更大的数据集上训练更复杂的模型已经成为可能，并且它们通常优于简单模型。最成功的概念可能是使用单词的分布式表示。例如，**基于神经网络的语言模型**显着优于 N-gram 模型。

### 1.1 Goals of the Paper 

>论文目标

本文的主要目标是介绍可用于从 **包含数十亿单词的庞大数据集 **中学习高质量 **词向量** 的技术。据我们所知，之前提出的架构都没有成功地训练过超过**几亿个单词**同时**单词向量的维数在 50 - 100 之间**的情况。



我们使用最近提出的技术来测量结果向量表示的质量，期望相似的单词可以彼此接近，同时单词可以具有多种相似度。早期在屈折语言的上下文中已经观察到了这一点 - 例如，名词可以有多个词尾，如果我们在原始向量空间的子空间中搜索相似的单词，就有可能找到具有相似词尾的单词。



有些惊讶的是，我们发现单词表示的相似性超出了简单的句法规则。使用 **词偏移技术（word offset technique）**，对词向量执行简单的代数运算，例如，向量（“King”）-向量（“Man”）+向量（“Woman”）会产生最接近的向量单词 Queen 的向量表示。



在本文中，我们尝试通过开发新的模型架构来最大限度地提高这些向量运算的准确性，以保留单词之间的线性规律。我们设计了一个**新的综合测试集**来测量句法和语义规律，并表明许多这样的规律可以高精度地学习。此外，我们还讨论了训练时间和准确性 和 词向量的维度以及训练数据量的关系。



### 1.2 Previous Work 

>前期工作

将单词表示为连续向量有着悠久的历史。 [1] 中提出了一种非常流行的用于估计神经网络语言模型（NNLM）的模型架构，其中使用具有线性投影层和非线性隐藏层的前馈神经网络来联合学习词向量表示和统计语言模型。这项工作已被许多其他工作所效仿。



[13, 14] 中提出了另一个有趣的 NNLM 架构，其中首先使用了具有单个隐藏层的神经网络来学习词向量。然后使用词向量来训练 NNLM。**因此，即使不构建完整的 NNLM，也可以学习词向量。**在这项工作中，我们直接扩展了这个架构，并只关注第一步，即**使用简单的模型学习词向量**。



后来表明，词向量可用于改进和简化许多 NLP 应用程序。词向量本身的估计是使用不同的模型架构进行的，并在各种语料库上进行训练，并且一些得到的词向量可用于未来的研究和比较。然而，据我们所知，这些架构的训练计算成本明显高于[13]中提出的架构，但使用对角权重矩阵的某些版本的对数双线性模型除外[23]。







## 2 Model Architectures 

> 一些模型架构

人们提出了许多不同类型的模型来估计单词的连续表示，包括众所周知的潜在语义分析（LSA）和潜在狄利克雷分配（LDA）。在本文中，我们重点关注**神经网络学习的单词的分布式表示**，因为之前的研究表明，它们在保留单词之间的线性规律方面明显优于 LSA [20, 31]；此外，LDA 在大型数据集上的计算成本非常高。



与[18]类似，为了比较不同的模型架构，我们首先将**模型的计算复杂度**定义为**完全训练模型所需访问的参数数量**。接下来，我们将尝试最大化准确性，同时最小化计算复杂度。



对于以下所有模型，训练复杂度与以下公式成正比


$$
O=E\times T\times Q
$$
其中 $E$ 是训练轮数，$T$ 是训练集中单词的数量，$Q$ 是为每个模型架构进一步定义的。常见的选择是 $E = 3 − 50$，$T$ 高达 10 亿。所有模型均使用**随机梯度下降**和**反向传播**进行训练[26]。

### 2.1 Feedforward Neural Net Language Model (NNLM)

> 前馈神经网络语言模型（NNLM）

由于投影层中的值很密集，因此 NNLM 架构对于投影和隐藏层之间的计算会非常复杂。对于 $N = 10$ 的常见选择，投影层 P 的大小可能为 500 到 2000，而隐藏层 H 的大小通常为 500 到 1000 个单位。此外，隐藏层用于计算词汇表中所有单词的概率分布，从而产生维度为 V 的输出层。因此，每个训练示例的计算复杂度可以表示为：
$$
Q = N × D + N × D × H + H × V
$$


其中主导项是 $H × V$ 。然而，为了避免这种情况，提出了几种实用的解决方案；要么使用softmax的分层版本[25,23,18]，要么通过使用训练期间未标准化的模型来完全避免标准化模型[4,9]。使用词汇表的二叉树表示，需要评估的输出单元的数量可以减少到 $log_2(V)$ 左右。因此，大部分复杂性是由 $N × D × H$ 项引起的。



在我们的模型中，我们使用**分层 softmax**，其中词汇表表示为**霍夫曼二叉树**。这是根据之前的观察得出的，即单词的频率对于在神经网络语言模型中获取类别非常有效[16]。霍夫曼树将短的二进制代码分配给频繁出现的单词，这进一步减少了需要评估的输出单元的数量：虽然平衡二叉树需要评估 复杂度为 $log_2(V)$ 输出，但基于霍夫曼树的分层 softmax 仅需要大约$\begin{aligned}log_2(Unigram_-perplexity(V))\end{aligned}$ 。例如，当词汇量大小为一百万个单词时，这会导致评估速度提高约两倍。虽然这对于神经网络 LM 来说并不是至关重要的加速，因为计算瓶颈在于 $N ×D ×H$ 项，但我们稍后将提出**没有隐藏层的架构**，因此在很大程度上依赖于 softmax 归一化的效率。



### 2.2 Recurrent Neural Net Language Model (RNNLM)

> 循环神经网络语言模型（RNNLM）

基于**循环神经网络**的语言模型已经被提出来克服**前馈神经网络** NNLM 的某些局限性，例如需要**指定上下文长度**（模型的阶数 N ），并且因为理论上 RNN 可以比浅层神经网络有效地表示更复杂的模式网络 [15, 2]。 **RNN模型没有投影层；只有输入层、隐藏层和输出层**。此类模型的特殊之处在于使用延时连接将隐藏层与其自身连接的循环矩阵。这允许循环模型形成某种短期记忆，因为过去的信息可以由隐藏层状态表示，该状态根据当前输入和前一个时间步骤中隐藏层的状态进行更新。

RNN 模型每个训练示例的复杂度为：
$$
Q=H\times H+H\times V
$$
其中单词表示 $D$ 与隐藏层 $H$  具有相同的维度。同样，通过使用分层 softmax，项 $H × V$ 可以有效地简化为 $H × log_2(V )$。大部分复杂性来自 $H × H$。



### 2.3 Parallel Training of Neural Networks

>神经网络的并行训练

为了在**巨大的数据集**上训练模型，我们在名为 DistBelief [6] 的大规模分布式框架之上实现了多个模型，包括**前馈 NNLM** 和 **本文提出的新模型**。该框架允许我们**并行运行同一模型的多个副本**，并且每个副本通过保留所有参数的集中式服务器同步其梯度更新。对于这种并行训练，我们使用**小批量异步梯度下降和称为 Adagrad 的自适应学习率**过程 [7]。在此框架下，通常使用一百个或更多模型副本，每个副本在数据中心的不同机器上使用许多 CPU 核心。



## 3 New Log-linear Models

> 新的对数线性模型

在本节中，我们提出了两种新的模型架构，用于学习单词的分布式表示，试图最大限度地减少计算复杂性。上一节的主要观察结果是，大部分复杂性是由模型中的**非线性隐藏层**引起的。虽然这就是神经网络如此有吸引力的原因，但我们决定探索更简单的模型，**这些模型可能无法像神经网络那样精确地表示数据，但可能可以有效地对更多数据进行训练**。



新的架构直接遵循我们早期工作[13, 14]中提出的架构，其中发现神经网络语言模型可以通过**两个步骤**成功训练：首先，使用**简单模型学习连续词向量**，然后**使用 N- gram NNLM 在这些单词的分布式表示之上进行训练**。虽然后来有大量工作集中在学习词向量上，但我们认为[13]中提出的方法是最简单的一种。请注意，相关模型也很早就被提出了[26, 8]。



### 3.1 Continuous Bag-of-Words Model

> CBOW 连续词袋模型

第一个提出的架构**类似于前馈 NNLM**，其中**非线性隐藏层被删除**，投影层为**所有单词（而不仅仅是投影矩阵）共享**；因此，所有单词都被投影到相同的位置（它们的向量被平均）。我们将这种架构称为**词袋模型**，因为历史中的单词顺序不会影响投影。此外，我们还使用未来的词语；通过构建一个输入有四个未来词和四个历史词的对数线性分类器，我们在下一节介绍的任务中获得了最佳性能，其中训练标准是正确分类当前（中间）词。训练复杂度为:
$$
 Q = N × D + D × log_2(V )
$$
我们将该模型进一步表示为 CBOW，因为与标准词袋模型不同，它使用上下文的连续分布式表示。模型架构如**图 1** 所示。请注意，输入层和投影层之间的权重矩阵以**与 NNLM 中相同的方式**为所有单词位置共享。



### 3.2 Continuous Skip-gram Model

> 连续Skip-gram模型

第二种架构与 CBOW 类似，但它不是根据上下文来预测当前单词，而是尝试根据同一句子中的另一个单词来最大化单词的分类。更准确地说，我们使用每个当前单词作为具有连续投影层的对数线性分类器的输入，并预测当前单词之前和之后一定范围内的单词。我们发现增加范围可以提高生成的词向量的质量，但也增加了计算复杂性。由于距离较远的单词通常与当前单词的相关性低于那些接近的单词，因此我们通过在训练示例中从这些单词中采样较少的样本来减少对距离较远的单词的权重。



